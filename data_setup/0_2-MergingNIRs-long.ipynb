{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Merging the NIRs data with text columns",
   "id": "fb74300f46e37b12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "# all data\n",
    "data_path = '../data'\n",
    "\n",
    "# nirs data\n",
    "nirs_data_sub1 = os.path.join(data_path, 'neuro/nirs_sub1.csv')\n",
    "nirs_data_sub2 = os.path.join(data_path, 'neuro/nirs_sub2.csv')\n",
    "\n",
    "# text data\n",
    "ceda_data_path = os.path.join(data_path, 'results/ceda-results.csv')\n",
    "########## may need to change . . . I need dyads->speakers data.\n",
    "meta_data_path = os.path.join(data_path, 'meta_data/CC_Post_105dyads.csv')"
   ],
   "id": "4a6d8c5b49990bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Import main data",
   "id": "9599af22aca4f8bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(ceda_data_path)\n",
    "df.head()"
   ],
   "id": "d11e75a515a95b9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dealing with TimeStamps",
   "id": "b55bb0c9eb1be938"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def to_NIRs_freq(t):\n",
    "    timestamp_pieces = t.split(':')\n",
    "    t = float(timestamp_pieces[-1])\n",
    "    if len(timestamp_pieces) > 1:\n",
    "        t+= (float(timestamp_pieces[-2]) * 60)\n",
    "    if len(timestamp_pieces) > 2:\n",
    "        t += (float(timestamp_pieces[-3]) * (60 * 60))\n",
    "    \n",
    "    return t * 5.0863"
   ],
   "id": "58638559104037b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dyad in tqdm(df['file'].unique()):\n",
    "    sub = df.loc[df['file'].isin([dyad])]\n",
    "    \n",
    "    if sub['timestamp'].loc[sub.index[0]] in [np.nan, None]:\n",
    "        sub['timestamp'].loc[sub.index[0]] = '00:00'\n",
    "        df['timestamp'].loc[sub.index[0]] = '00:00'\n",
    "    \n",
    "    no_markers = sub.loc[sub['timestamp'].isna()].index\n",
    "    has_marker = sub.loc[~sub['timestamp'].isna()].index\n",
    "    \n",
    "    for i in no_markers:\n",
    "        marker = has_marker[has_marker<i]\n",
    "        if len(marker) > 0:\n",
    "            marker = marker[-1]\n",
    "            df['timestamp'].loc[i] = df['timestamp'].loc[marker]\n",
    "        \n",
    "        # elif (i == sub.index[0]):\n",
    "        #     df['timestamp'].loc[i] = '00:00'\n",
    "        \n",
    "df.head(20)"
   ],
   "id": "bcd64a6cc2d2847e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df['NIRS_time'] = [to_NIRs_freq(t) for t in tqdm(df['timestamp'].values)]",
   "id": "e7fb88224a5e5988",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[['file', 'NIRS_time']].head()",
   "id": "2a4bf05db116dab8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['next_NIRS_time'] = None\n",
    "\n",
    "for dyad in tqdm(df['file'].unique()):\n",
    "    sub = df.loc[df['file'].isin([dyad])]\n",
    "    for i in sub.index:\n",
    "        t_ = sub['NIRS_time'].loc[i]\n",
    "        s_ = sub['NIRS_time'].loc[sub['NIRS_time'] > t_].values\n",
    "        \n",
    "        if len(s_) > 0:\n",
    "            df['next_NIRS_time'].loc[i] = s_[0]\n",
    "        \n",
    "        elif i == sub.index[-1]:\n",
    "            df['next_NIRS_time'].loc[i] = 1e9\n",
    "        \n",
    "        else:\n",
    "            df['next_NIRS_time'].loc[i] = sub['NIRS_time'].max()\n",
    "        \n",
    "df[['file','NIRS_time', 'next_NIRS_time']].head(20)"
   ],
   "id": "36332689241632f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['next_next_NIRS_time'] = None\n",
    "\n",
    "for dyad in tqdm(df['file'].unique()):\n",
    "    sub = df.loc[df['file'].isin([dyad])]\n",
    "    for i in sub.index:\n",
    "        t_ = sub['NIRS_time'].loc[i]\n",
    "        s_ = sub['NIRS_time'].loc[sub['NIRS_time'] > t_].unique()\n",
    "        \n",
    "        if len(s_) > 1:\n",
    "            df['next_next_NIRS_time'].loc[i] = s_[1]\n",
    "        \n",
    "        elif i == sub.index[-1]:\n",
    "            df['next_next_NIRS_time'].loc[i] = 1e9\n",
    "        \n",
    "        else:\n",
    "            df['next_next_NIRS_time'].loc[i] = sub['next_NIRS_time'].loc[i]\n",
    "        \n",
    "df[['file','NIRS_time', 'next_NIRS_time', 'next_next_NIRS_time']].head(20)"
   ],
   "id": "6ce7433c63b43eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['NIRS_time'] = [np.ceil(t) for t in tqdm(df['NIRS_time'].values)]\n",
    "df['next_NIRS_time'] = [np.floor(t) for t in tqdm(df['next_NIRS_time'].values)]\n",
    "df['next_next_NIRS_time'] = [np.floor(t) for t in tqdm(df['next_next_NIRS_time'].values)]\n",
    "df[['file','NIRS_time', 'next_NIRS_time', 'next_next_NIRS_time']].head(20)"
   ],
   "id": "f0435a2d73432613",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Process",
   "id": "c1263759ba0f46f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Per conversation ID, streaming fNIRs data and grabbing the appropriate speakers.",
   "id": "a2a738f86c24abbb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "unified_neuro_home = os.path.join(data_path, 'unified_neuro')\n",
    "fnirs_files = [\n",
    "    os.path.join(unified_neuro_home, f) for f in os.listdir(unified_neuro_home) \n",
    "    if (not f.startswith('._'))\n",
    "]\n",
    "# fnirs_files"
   ],
   "id": "56a698a887f8a449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "channel_indexes = {\n",
    "    \"L_lPFC\": ['ch_'+str(i) for i in range(1,6+1)],\n",
    "    \"mPFC\": ['ch_'+str(i) for i in range(7,14+1)],\n",
    "    \"R_lPFC\": ['ch_'+str(i) for i in range(15,20+1)],\n",
    "    \"L_SPL\": ['ch_'+str(i) for i in range(21,23+1)],\n",
    "    \"L_TPJ\": ['ch_'+str(i) for i in range(24,30+1)],\n",
    "    \"R_SPL\": ['ch_'+str(i) for i in range(31,33+1)],\n",
    "    \"R_TPJ\": ['ch_'+str(i) for i in range(34,40+1)],\n",
    "}"
   ],
   "id": "32c4986cea719a21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "channel_to_region_names = dict()\n",
    "for k, v in channel_indexes.items():\n",
    "    for i,channel in enumerate(v):\n",
    "        channel_to_region_names[channel] = k + '_ch_' + str(i+1)"
   ],
   "id": "e5754bae3371c3ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_channels = sum(channel_indexes.values(), [])\n",
    "df[all_channels] = None\n",
    "\n",
    "for dyad in tqdm(df['file'].unique()):\n",
    "    sub = df.loc[df['file'].isin([dyad])].index.values\n",
    "    fnirs_data = [f for f in fnirs_files if str(dyad) in f][0]\n",
    "    fnirs_data = pd.read_csv(fnirs_data)\n",
    "\n",
    "    # make the next time stamp for all the conversation, for the last turn, \n",
    "    #  be the end of the conversation...\n",
    "    # if df['next_NIRS_time'].loc[sub[-1]] == df['next_next_NIRS_time'].loc[sub[-1]]:\n",
    "    #     df['next_NIRS_time'].loc[sub[-1]] = len(fnirs_data)\n",
    "    df['next_next_NIRS_time'].loc[sub[-1]] = len(fnirs_data)\n",
    "    \n",
    "    if df['next_NIRS_time'].loc[sub[-1]] in [np.nan, None]:\n",
    "        df['next_NIRS_time'] = len(fnirs_data)\n",
    "\n",
    "    ## DO SOMETHING\n",
    "    for start_t, end_t in df[['NIRS_time','next_NIRS_time']].loc[sub].drop_duplicates().values:\n",
    "        values = fnirs_data[all_channels].loc[\n",
    "            (fnirs_data['Time'] >= start_t)\n",
    "            & (fnirs_data['Time'] < end_t)\n",
    "        ]\n",
    "        \n",
    "        mu = np.nan_to_num(values.mean(axis=0).values)\n",
    "        \n",
    "        sel = df['NIRS_time'].isin([start_t]) & df['next_NIRS_time'].isin([end_t]) & df.index.isin(sub)\n",
    "        \n",
    "        for i in range(mu.shape[0]):\n",
    "            df[all_channels[i]].loc[sel] = mu[i]\n"
   ],
   "id": "f86954f5bf055a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[['file', 'nx', 'ny', 'Hxy']+all_channels[:5]].head()",
   "id": "c2e152c325295fab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_new_channels = ['next_'+col for col in sum(channel_indexes.values(), [])]\n",
    "df[all_new_channels] = None\n",
    "\n",
    "for dyad in tqdm(df['file'].unique()):\n",
    "    sub = df.loc[df['file'].isin([dyad])].index.values\n",
    "    fnirs_data = [f for f in fnirs_files if str(dyad) in f][0]\n",
    "    fnirs_data = pd.read_csv(fnirs_data)\n",
    "\n",
    "    ## DO SOMETHING\n",
    "    for start_t, end_t in df[['NIRS_time','next_next_NIRS_time']].loc[sub].drop_duplicates().values:\n",
    "        values = fnirs_data[all_channels].loc[\n",
    "            (fnirs_data['Time'] >= start_t)\n",
    "            & (fnirs_data['Time'] < end_t)\n",
    "        ]\n",
    "        \n",
    "        mu = values.mean(axis=0).values\n",
    "        \n",
    "        sel = df['NIRS_time'].isin([start_t]) & df['next_next_NIRS_time'].isin([end_t]) & df.index.isin(sub)\n",
    "        \n",
    "        for i in range(mu.shape[0]):\n",
    "            df[all_new_channels[i]].loc[sel] = mu[i]\n"
   ],
   "id": "bd40b57a72615e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[['file', 'nx', 'ny', 'Hxy']+all_new_channels[:5]].head()",
   "id": "cd198b0a52a4e947",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df.rename(columns=channel_to_region_names)\n",
    "\n",
    "### next_ region names\n",
    "channel_to_region_names2 = dict()\n",
    "for k,v in channel_to_region_names.items():\n",
    "    channel_to_region_names2['next_'+k] = 'next_'+v\n",
    "df = df.rename(columns=channel_to_region_names2)\n",
    "\n",
    "# [col for col in list(df) if '_ch_' in col]"
   ],
   "id": "24effeee400e7e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_csv(ceda_data_path.replace('.csv', '-with_fNIRs-long.csv'), index=False, encoding='utf-8')",
   "id": "8b0d16afeacc0ac7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fdc59b3de8583543"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
